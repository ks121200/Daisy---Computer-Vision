{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wSLTGrsZ27YW",
        "outputId": "b0c76ecd-beeb-42dd-aa02-b6d700198f59"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3oJmgt-2-zK",
        "outputId": "3009d30f-57a4-4553-8219-e1a7cee1188a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqRqzDDG3HpS"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "train_dir = '/content/drive/MyDrive/DAISY2.0 Data/data/train'\n",
        "validation_dir = '/content/drive/MyDrive/DAISY2.0 Data/data/validation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPtZ4Sol3JPe"
      },
      "outputs": [],
      "source": [
        "# Data augmentation and rescaling\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz487oQu3J3p"
      },
      "outputs": [],
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFcLjfGs3MIJ",
        "outputId": "46f0035b-a786-4766-a056-83e5edccf273"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=8,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Load and preprocess validation data\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=8,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhUWAhUN3O9L",
        "outputId": "1cae01bb-9ff0-4046-ee6e-a67a48520f1f"
      },
      "outputs": [],
      "source": [
        "# Print dataset information\n",
        "print(f\"Training set: {train_generator.samples} images belonging to {train_generator.num_classes} classes.\")\n",
        "print(f\"Validation set: {validation_generator.samples} images belonging to {validation_generator.num_classes} classes.\")\n",
        "print(f\"Class indices: {train_generator.class_indices}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIXhbZJd3UWr",
        "outputId": "b2c4262f-34ee-4b9c-cbc2-aba5cf8b4bb4"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available and set up the environment to use GPU\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU found')\n",
        "else:\n",
        "    print(\"No GPU found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCM7bSw73Zk4"
      },
      "outputs": [],
      "source": [
        "def unet_model(input_size=(128, 128, 3)):  # Adjust input size\n",
        "    inputs = tf.keras.layers.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "    c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "    c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    # Decoder\n",
        "    u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "    c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "    c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "    c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "    c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "    c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "    c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "    c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "    c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    # Classification output layer\n",
        "    flatten = tf.keras.layers.Flatten()(c9)\n",
        "    dense1 = tf.keras.layers.Dense(1024, activation='relu')(flatten)\n",
        "    dropout1 = tf.keras.layers.Dropout(0.5)(dense1)\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(dropout1)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[output])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNNtKu8a3dW2",
        "outputId": "28562a1a-440c-441e-e8ad-c87b6a2b5157"
      },
      "outputs": [],
      "source": [
        "# Instantiate and compile the model\n",
        "model = unet_model(input_size=(128, 128, 3))\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6tEsq4h3tMA",
        "outputId": "981fd221-9f98-4821-8c0d-ef2793f0d86d"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0itLaCIFWmO",
        "outputId": "45d79770-f5b4-4527-cd7d-c11ef265d068"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('unet_model_for_classification.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4xUA1xaGqVi"
      },
      "outputs": [],
      "source": [
        "# Define the path to save the model\n",
        "save_path = '/content/drive/MyDrive/DAISY2.0 Data'\n",
        "\n",
        "# Save the model to Google Drive\n",
        "model.save(save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uPnggTuFjlQ",
        "outputId": "5937e319-2fef-4a19-c7d6-75a6363e7299"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('unet_model_for_classification.h5')\n",
        "\n",
        "# Function to preprocess the image\n",
        "def preprocess_image(img_path, target_size=(128, 128)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array /= 255.0  # Normalize the image\n",
        "    return img_array\n",
        "\n",
        "# Path to the single image you want to test\n",
        "img_path = '/content/drive/MyDrive/DAISY2.0 Data/data/train/no_holes/Antisolvent_IPA_2_1.tif'\n",
        "\n",
        "# Preprocess the image\n",
        "preprocessed_image = preprocess_image(img_path)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(preprocessed_image)\n",
        "\n",
        "# Output the prediction\n",
        "print(f\"Prediction: {prediction[0][0]}\")\n",
        "if prediction[0][0] > 0.5:\n",
        "    print(\"Class: Positive (Defect)\")\n",
        "else:\n",
        "    print(\"Class: Negative (No Defect)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "collapsed": true,
        "id": "aHCn4fFYGXV7",
        "outputId": "487dcb73-810a-4787-91a5-48e8695deb4b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('unet_model_for_classification.h5')\n",
        "\n",
        "# Define paths\n",
        "validation_dir = '/content/drive/MyDrive/DAISY2.0 Data/data/validation'\n",
        "\n",
        "# Rescaling for validation set\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Set the batch size\n",
        "batch_size = 8\n",
        "\n",
        "# Load and preprocess validation data\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(128, 128),  # Match the input size of the model\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Do not shuffle to keep order\n",
        ")\n",
        "\n",
        "# Get the ground truth labels\n",
        "y_true = validation_generator.classes\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(validation_generator)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)  # Convert probabilities to binary predictions\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# To display confusion matrix in a readable format (optional)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
